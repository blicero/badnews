# -*- mode: org; fill-column: 78; -*-
# Time-stamp: <2024-11-30 20:17:44 krylon>
#
#+TAGS: internals(i) ui(u) bug(b) feature(f)
#+TAGS: database(d) design(e), meditation(m)
#+TAGS: optimize(o) refactor(r) cleanup(c)
#+TAGS: web(w)
#+TODO: TODO(t)  RESEARCH(r) IMPLEMENT(i) TEST(e) | DONE(d) FAILED(f) CANCELLED(c)
#+TODO: MEDITATE(m) PLANNING(p) | SUSPENDED(s)
#+PRIORITIES: A G D

* BadNews [29/33]
  :PROPERTIES:
  :COOKIE_DATA: todo recursive
  :VISIBILITY: children
  :END:
  BadNews is an RSS reader
** Clock table
   #+BEGIN: clocktable :scope file :maxlevel 202 :emphasize t
   #+CAPTION: Clock summary at [2024-11-30 Sa 20:17]
   | Headline                                             | Time       |            |          |          |       |      |
   |------------------------------------------------------+------------+------------+----------+----------+-------+------|
   | *Total time*                                         | *7d 17:25* |            |          |          |       |      |
   |------------------------------------------------------+------------+------------+----------+----------+-------+------|
   | *BadNews [29/33]*                                    | *7d 17:25* |            |          |          |       |      |
   | \_  /Features [14/14]/                               |            | /2d 12:49/ |          |          |       |      |
   | \_    Blacklisting [1/1]                             |            |            |     6:03 |          |       |      |
   | \_    Rating and Tagging [12/12]                     |            |            |  2d 6:46 |          |       |      |
   | \_      Rating [2/2]                                 |            |            |          |     9:15 |       |      |
   | \_        Hide boring Items                          |            |            |          |          |  2:45 |      |
   | \_        Caching results                            |            |            |          |          |  0:27 |      |
   | \_      Tags [9/9]                                   |            |            |          | 1d 21:30 |       |      |
   | \_        Re-render everything tag when editing...   |            |            |          |          |  0:56 |      |
   | \_        Recommend tags for Items                   |            |            |          |          |  5:59 |      |
   | \_          Don't recommend Tags the Item already... |            |            |          |          |       | 0:57 |
   | \_        Add newly created tags to tag_view         |            |            |          |          |  1:20 |      |
   | \_        Order tags by hierarchy                    |            |            |          |          |  1:10 |      |
   | \_        Link Tags to Items [3/3]                   |            |            |          |          | 14:24 |      |
   | \_          Disable linked Tags in menu              |            |            |          |          |       | 1:13 |
   | \_          Unlink Tags from Items                   |            |            |          |          |       | 1:13 |
   | \_          Fetch linked tags per item in handler... |            |            |          |          |       | 0:23 |
   | \_  /Components [15/19]/                             |            | /5d 4:36/  |          |          |       |      |
   | \_    Data model [3/3]                               |            |            |     5:25 |          |       |      |
   | \_      Feeds [3/3]                                  |            |            |          |     4:58 |       |      |
   | \_        Delete Feeds [2/2]                         |            |            |          |          |  4:58 |      |
   | \_          Delete from database                     |            |            |          |          |       | 3:00 |
   | \_          Clean up the Bayesian models             |            |            |          |          |       | 0:15 |
   | \_    Database [1/1]                                 |            |            |    12:17 |          |       |      |
   | \_      Testing [0/0]                                |            |            |          |     3:02 |       |      |
   | \_      Queries respect transaction                  |            |            |          |     0:03 |       |      |
   | \_    Feed catcher / parser [0/0]                    |            |            |     5:41 |          |       |      |
   | \_      Testing                                      |            |            |          |     2:16 |       |      |
   | \_    Web Interface [8/12]                           |            |            | 1d 21:59 |          |       |      |
   | \_      Search [1/3]                                 |            |            |          |    21:21 |       |      |
   | \_        Overview                                   |            |            |          |          |  7:00 |      |
   | \_        Form                                       |            |            |          |          | 13:30 |      |
   | \_      Feeds overview                               |            |            |          |     1:42 |       |      |
   | \_      Message Area                                 |            |            |          |     7:10 |       |      |
   | \_      Appearances matter [5/5]                     |            |            |          |     4:40 |       |      |
   | \_        Feed Details                               |            |            |          |          |  0:57 |      |
   | \_          Sort Feeds by Title                      |            |            |          |          |       | 0:16 |
   | \_        Images                                     |            |            |          |          |  0:12 |      |
   | \_        Hide long descriptions                     |            |            |          |          |  0:20 |      |
   | \_        Fix Links                                  |            |            |          |          |  0:03 |      |
   | \_      AJAX FTW [0/0]                               |            |            |          |     3:02 |       |      |
   | \_    Tag Advisor [2/2]                              |            |            |    11:29 |          |       |      |
   | \_      Performance [2/2]                            |            |            |          |    10:10 |       |      |
   | \_        Caching                                    |            |            |          |          |  3:06 |      |
   | \_        Pre-computing advice                       |            |            |          |          |  7:04 |      |
   | \_    Search [1/1]                                   |            |            | 1d 19:45 |          |       |      |
   | \_      Execute Searches                             |            |            |          |    14:57 |       |      |
   #+END:
** Journal
** Features [14/14]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
*** DONE Blacklisting [1/1]
    CLOSED: [2024-11-04 Mo 19:06]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2024-11-04 Mo 17:40]--[2024-11-04 Mo 19:06] =>  1:26
    CLOCK: [2024-11-02 Sa 19:50]--[2024-11-02 Sa 21:51] =>  2:01
    CLOCK: [2024-11-02 Sa 17:44]--[2024-11-02 Sa 19:23] =>  1:39
    CLOCK: [2024-11-01 Fr 15:58]--[2024-11-01 Fr 16:55] =>  0:57
    :END:
    I would like to be able to blacklist items based on regular expressions,
    so they never find their way into the database (ideally) or are not
    displayed in the web UI.
**** DONE Storage
     CLOSED: [2024-11-02 Sa 19:50]
     Do I store the patterns in the database?
     [2024-11-02 Sa 19:50] -- I dump the blacklist to a JSON document, at
     least for the time being. No need to get fancy. If SQLite had native
     support for regular expressions, I would use it, but it doesn't, so I
     don't.
*** Rating and Tagging [12/12]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2024-10-02 Mi 21:09]--[2024-10-02 Mi 21:10] =>  0:01
    :END:
    I want to take the opportunity to rethink the way I did the tagging and
    rating in the old ticker app.
**** DONE Rating [2/2]
     CLOSED: [2024-10-20 So 17:07]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2024-10-07 Mo 12:33]--[2024-10-07 Mo 16:09] =>  3:36
     CLOCK: [2024-10-04 Fr 17:37]--[2024-10-04 Fr 20:04] =>  2:27
     :END:
     On the database side, I already did some preparations.

     [2024-10-04 Fr 20:09]
     Okay, I can rate and un-rate items now, now I need a kind of Bayesian net
     to guess how interesting or boring the other items are.
***** SUSPENDED Hide boring Items
      CLOSED: [2024-11-10 So 16:45]
      :LOGBOOK:
      CLOCK: [2024-10-31 Do 20:15]--[2024-10-31 Do 23:00] =>  2:45
      :END:
      I would like Items that I have marked explicitly as boring to not be
      shown in the news ticker.
***** DONE Caching results
      CLOSED: [2024-10-07 Mo 16:09]
      :LOGBOOK:
      CLOCK: [2024-10-07 Mo 12:06]--[2024-10-07 Mo 12:33] =>  0:27
      :END:
      I want to cache results computed by the Judge, but I am unsure how I
      want to do that. I could just use the database - it's already there,
      isn't it? -, but I could use something else, too, so I don't create an
      accidental bottleneck. LevelDB for example, which claims to be pretty
      fast.
**** Tags [9/9]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2024-10-28 Mo 19:59]--[2024-10-28 Mo 20:36] =>  0:37
     CLOCK: [2024-10-26 Sa 18:30]--[2024-10-26 Sa 22:23] =>  3:53
     CLOCK: [2024-10-14 Mo 14:30]--[2024-10-14 Mo 16:05] =>  1:35
     CLOCK: [2024-10-13 So 18:47]--[2024-10-13 So 20:15] =>  1:28
     CLOCK: [2024-10-13 So 14:40]--[2024-10-13 So 18:36] =>  3:56
     CLOCK: [2024-10-12 Sa 15:52]--[2024-10-12 Sa 18:10] =>  2:18
     CLOCK: [2024-10-11 Fr 21:30]--[2024-10-11 Fr 22:45] =>  1:15
     CLOCK: [2024-10-11 Fr 18:25]--[2024-10-11 Fr 18:51] =>  0:26
     CLOCK: [2024-10-09 Mi 15:34]--[2024-10-09 Mi 19:45] =>  4:11
     CLOCK: [2024-10-08 Di 18:14]--[2024-10-08 Di 19:41] =>  1:27
     CLOCK: [2024-10-08 Di 14:56]--[2024-10-08 Di 15:31] =>  0:35
     :END:
***** DONE Re-render everything tag when editing tags
      CLOSED: [2024-10-28 Mo 19:59]
      :LOGBOOK:
      CLOCK: [2024-10-25 Fr 17:52]--[2024-10-25 Fr 18:48] =>  0:56
      :END:
***** DONE Recommend tags for Items
      CLOSED: [2024-10-28 Mo 19:59]
      :LOGBOOK:
      CLOCK: [2024-10-25 Fr 17:17]--[2024-10-25 Fr 17:51] =>  0:34
      CLOCK: [2024-10-24 Do 19:44]--[2024-10-24 Do 22:46] =>  3:02
      CLOCK: [2024-10-23 Mi 13:24]--[2024-10-23 Mi 14:50] =>  1:26
      :END:
      I had this feature on my previous ticker application, but I suspect it
      is very, very slow. On this retry, I'd like have acceptable performance,
      even if the app is running on a lowly Raspberry Pi Model 2.
****** DONE Don't recommend Tags the Item already has
       CLOSED: [2024-10-28 Mo 21:33]
       :LOGBOOK:
       CLOCK: [2024-10-28 Mo 20:36]--[2024-10-28 Mo 21:33] =>  0:57
       :END:
***** DONE Add newly created tags to tag_view
      CLOSED: [2024-10-17 Do 16:47]
      :LOGBOOK:
      CLOCK: [2024-10-17 Do 15:27]--[2024-10-17 Do 16:47] =>  1:20
      :END:
***** DONE Order tags by hierarchy
      CLOSED: [2024-10-21 Mo 17:41]
      :LOGBOOK:
      CLOCK: [2024-10-21 Mo 16:31]--[2024-10-21 Mo 17:41] =>  1:10
      :END:
***** DONE Link Tags to Items [3/3]
      CLOSED: [2024-10-21 Mo 17:41]
      :PROPERTIES:
      :COOKIE_DATA: todo recursive
      :VISIBILITY: children
      :END:
      :LOGBOOK:
      CLOCK: [2024-10-19 Sa 17:34]--[2024-10-19 Sa 20:35] =>  3:01
      CLOCK: [2024-10-18 Fr 18:18]--[2024-10-18 Fr 23:19] =>  5:01
      CLOCK: [2024-10-17 Do 21:57]--[2024-10-17 Do 23:30] =>  1:33
      CLOCK: [2024-10-17 Do 17:52]--[2024-10-17 Do 19:52] =>  2:00
      :END:
****** DONE Disable linked Tags in menu
       CLOSED: [2024-10-28 Mo 23:48]
       :LOGBOOK:
       CLOCK: [2024-10-28 Mo 22:35]--[2024-10-28 Mo 23:48] =>  1:13
       :END:
****** DONE Unlink Tags from Items
       CLOSED: [2024-10-20 So 18:22]
       :LOGBOOK:
       CLOCK: [2024-10-20 So 17:09]--[2024-10-20 So 18:22] =>  1:13
       :END:
****** DONE Fetch linked tags per item in handler for item_view         :web:
      CLOSED: [2024-10-19 Sa 21:59]
      :LOGBOOK:
      CLOCK: [2024-10-19 Sa 20:37]--[2024-10-19 Sa 21:00] =>  0:23
      :END:
** Components [15/19]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
*** Data model [3/3]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2024-09-19 Do 16:25]--[2024-09-19 Do 16:52] =>  0:27
    :END:
**** Feeds [3/3]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
***** DONE Delete Feeds [2/2]
      CLOSED: [2024-11-12 Di 20:00]
      :PROPERTIES:
      :COOKIE_DATA: todo recursive
      :VISIBILITY: children
      :END:
      :LOGBOOK:
      CLOCK: [2024-11-12 Di 18:17]--[2024-11-12 Di 20:00] =>  1:43
      CLOCK: [2024-11-11 Mo 18:20]--[2024-11-11 Mo 18:20] =>  0:00
      :END:
****** DONE Delete from database
       CLOSED: [2024-11-12 Di 20:00]
       :LOGBOOK:
       CLOCK: [2024-11-12 Di 14:41]--[2024-11-12 Di 15:37] =>  0:56
       CLOCK: [2024-11-11 Mo 20:08]--[2024-11-11 Mo 21:05] =>  0:57
       CLOCK: [2024-11-11 Mo 18:20]--[2024-11-11 Mo 19:27] =>  1:07
       :END:
       That means:
       - [X] Delete all links between Tags and Items from this Feed.
       - [X] Delete the Items
       - [X] Delete the Feed
****** SUSPENDED Clean up the Bayesian models
       CLOSED: [2024-11-12 Di 18:12]
       :LOGBOOK:
       CLOCK: [2024-11-12 Di 18:11]--[2024-11-12 Di 18:12] =>  0:01
       CLOCK: [2024-11-12 Di 17:42]--[2024-11-12 Di 17:56] =>  0:14
       :END:
       I may be lazy and just reset the models and generate them anew.
       We'll see.
       ...
       On second thought, I might not, in fact, need to clean up the training
       data for the Bayesian models. I *did* make those associations, after
       all. And that part won't use up all that much space.
       And if I really need to, I can just discard the existing training data
       and train the models anew. 
*** Database [1/1]                                                 :database:
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2024-10-15 Di 16:21]--[2024-10-15 Di 17:06] =>  0:45
    CLOCK: [2024-10-01 Di 18:27]--[2024-10-01 Di 18:35] =>  0:08
    CLOCK: [2024-09-24 Di 14:42]--[2024-09-24 Di 14:44] =>  0:02
    CLOCK: [2024-09-23 Mo 20:45]--[2024-09-23 Mo 21:37] =>  0:52
    CLOCK: [2024-09-21 Sa 20:35]--[2024-09-21 Sa 20:42] =>  0:07
    CLOCK: [2024-09-21 Sa 15:52]--[2024-09-21 Sa 16:00] =>  0:08
    CLOCK: [2024-09-21 Sa 13:52]--[2024-09-21 Sa 15:41] =>  1:49
    CLOCK: [2024-09-20 Fr 21:10]--[2024-09-20 Fr 21:46] =>  0:36
    CLOCK: [2024-09-20 Fr 10:19]--[2024-09-20 Fr 10:55] =>  0:36
    CLOCK: [2024-09-19 Do 16:52]--[2024-09-19 Do 21:01] =>  4:09
    :END:
**** Testing [0/0]
     :LOGBOOK:
     CLOCK: [2024-10-13 So 18:36]--[2024-10-13 So 18:47] =>  0:11
     CLOCK: [2024-10-12 Sa 18:10]--[2024-10-12 Sa 21:01] =>  2:51
     :END:
**** DONE [#A] Queries respect transaction                              :bug:
     CLOSED: [2024-09-24 Di 19:08]
     :LOGBOOK:
     CLOCK: [2024-09-24 Di 19:05]--[2024-09-24 Di 19:08] =>  0:03
     :END:
     All database methods that query the database but do not change it, need
     to check if the database has an ongoing transaction and if so, need to
     use =stmt = db.tx.Stmt(stmt)=.
     [2024-09-24 Di 19:06] Turns out, I /already/ do that. Which is both a bit
     embarassing (insofar I did not remember) and a relief (insofar I
     obviously did think of this before).
*** Feed catcher / parser [0/0]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2024-09-24 Di 19:08]--[2024-09-24 Di 20:06] =>  0:58
    CLOCK: [2024-09-24 Di 17:18]--[2024-09-24 Di 19:05] =>  1:47
    CLOCK: [2024-09-24 Di 14:45]--[2024-09-24 Di 15:25] =>  0:40
    :END:
**** Testing
     :LOGBOOK:
     CLOCK: [2024-09-26 Do 17:56]--[2024-09-26 Do 20:12] =>  2:16
     :END:
*** Web Interface [8/12]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2024-10-30 Mi 17:56]--[2024-10-30 Mi 19:30] =>  1:34
    CLOCK: [2024-10-08 Di 14:48]--[2024-10-08 Di 14:53] =>  0:05
    CLOCK: [2024-09-30 Mo 18:27]--[2024-09-30 Mo 23:50] =>  5:23
    CLOCK: [2024-09-30 Mo 17:50]--[2024-09-30 Mo 18:21] =>  0:31
    CLOCK: [2024-09-30 Mo 13:35]--[2024-09-30 Mo 13:46] =>  0:11
    CLOCK: [2024-09-29 So 16:10]--[2024-09-29 So 16:30] =>  0:20
    :END:
    For an RSS reader, a web interface is the obvious approach, isn't it?
**** TODO Search [1/3]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2024-11-19 Di 18:16]--[2024-11-19 Di 19:01] =>  0:45
     CLOCK: [2024-11-19 Di 15:19]--[2024-11-19 Di 15:25] =>  0:06
     :END:
***** TODO Overview
      :LOGBOOK:
      CLOCK: [2024-11-21 Do 18:25]--[2024-11-21 Do 19:17] =>  0:52
      CLOCK: [2024-11-21 Do 14:09]--[2024-11-21 Do 14:35] =>  0:26
      CLOCK: [2024-11-20 Mi 16:21]--[2024-11-20 Mi 20:32] =>  4:11
      CLOCK: [2024-11-20 Mi 13:10]--[2024-11-20 Mi 14:41] =>  1:31
      :END:
***** DONE Form
      CLOSED: [2024-11-30 Sa 20:17]
      :LOGBOOK:
      CLOCK: [2024-11-30 Sa 19:51]--[2024-11-30 Sa 20:16] =>  0:25
      CLOCK: [2024-11-29 Fr 17:31]--[2024-11-29 Fr 17:55] =>  0:24
      CLOCK: [2024-11-28 Do 14:03]--[2024-11-28 Do 16:15] =>  2:12
      CLOCK: [2024-11-25 Mo 17:19]--[2024-11-25 Mo 19:27] =>  2:08
      CLOCK: [2024-11-24 So 19:14]--[2024-11-24 So 19:19] =>  0:05
      CLOCK: [2024-11-24 So 15:27]--[2024-11-24 So 15:51] =>  0:24
      CLOCK: [2024-11-24 So 14:31]--[2024-11-24 So 14:50] =>  0:19
      CLOCK: [2024-11-22 Fr 15:36]--[2024-11-22 Fr 19:55] =>  4:19
      CLOCK: [2024-11-21 Do 19:17]--[2024-11-21 Do 21:38] =>  2:21
      CLOCK: [2024-11-21 Do 14:35]--[2024-11-21 Do 15:28] =>  0:53
      :END:
***** TODO Result View
**** TODO Paged Item view
     Since we are doing AJAX, I could get away without reloading the entire
     page. Not sure whether this is a good idea or not, but I think reloading
     is in order, so that I can have a URL that refers to the specific page.
     I could give the offset as a timestamp or offset in the URL.
**** DONE Feeds overview
     CLOSED: [2024-10-31 Do 17:43]
     :LOGBOOK:
     CLOCK: [2024-10-31 Do 01:00]--[2024-10-31 Do 01:48] =>  0:48
     CLOCK: [2024-10-31 Do 00:05]--[2024-10-31 Do 00:59] =>  0:54
     :END:
**** DONE Message Area
     CLOSED: [2024-10-30 Mi 16:28]
     :LOGBOOK:
     CLOCK: [2024-10-29 Di 15:10]--[2024-10-29 Di 20:04] =>  4:54
     CLOCK: [2024-10-29 Di 10:13]--[2024-10-29 Di 12:29] =>  2:16
     :END:
     I would like to have an area to display messages, e.g. for failed AJAX requests.
**** Appearances matter [5/5]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2024-10-01 Di 19:39]--[2024-10-01 Di 22:47] =>  3:08
     :END:
***** DONE Feed Details
     CLOSED: [2024-10-11 Fr 15:30]
     :LOGBOOK:
     CLOCK: [2024-10-11 Fr 14:49]--[2024-10-11 Fr 15:30] =>  0:41
     :END:
****** DONE Sort Feeds by Title
       CLOSED: [2024-11-04 Mo 19:23]
       :LOGBOOK:
       CLOCK: [2024-11-04 Mo 19:07]--[2024-11-04 Mo 19:23] =>  0:16
       :END:
***** DONE Images
      CLOSED: [2024-10-02 Mi 18:14]
      :LOGBOOK:
      CLOCK: [2024-10-02 Mi 18:02]--[2024-10-02 Mi 18:14] =>  0:12
      :END:
      This is something I tackled but didn't get right with the old app, I
      /want/ to have images referenced in the RSS descriptions displayed, but
      I want them to be modestly sized.
***** DONE Hide long descriptions
      CLOSED: [2024-10-02 Mi 18:35]
      :LOGBOOK:
      CLOCK: [2024-10-02 Mi 18:15]--[2024-10-02 Mi 18:35] =>  0:20
      :END:
      In the old ticker app, I would hide lengthy article descriptions behind
      a button that would reveal the entire text + images. I should just copy
      that verbatim.
***** DONE Fix Links
      CLOSED: [2024-10-02 Mi 18:38]
      :LOGBOOK:
      CLOCK: [2024-10-02 Mi 18:35]--[2024-10-02 Mi 18:38] =>  0:03
      :END:
      I want to make sure any links within item descriptions are opened in new
      tabs or windows.
**** AJAX FTW [0/0]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2024-10-01 Di 18:55]--[2024-10-01 Di 19:29] =>  0:34
     CLOCK: [2024-10-01 Di 18:35]--[2024-10-01 Di 18:51] =>  0:16
     CLOCK: [2024-10-01 Di 17:25]--[2024-10-01 Di 18:27] =>  1:02
     CLOCK: [2024-10-01 Di 14:15]--[2024-10-01 Di 15:25] =>  1:10
     :END:
     In my current news reader, loading the items views takes about forever,
     and one main goal of the rewrite is to make it at least feel more
     responsive. So I am going to try and load as much of the content as
     possible via Ajax.
*** Tag Advisor [2/2]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2024-10-22 Di 17:09]--[2024-10-22 Di 17:23] =>  0:14
    CLOCK: [2024-10-22 Di 14:35]--[2024-10-22 Di 15:40] =>  1:05
    :END:
**** Performance [2/2]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
***** DONE Caching
      CLOSED: [2024-10-31 Do 19:42]
      :LOGBOOK:
      CLOCK: [2024-11-08 Fr 17:20]--[2024-11-08 Fr 18:54] =>  1:34
      CLOCK: [2024-10-31 Do 18:55]--[2024-10-31 Do 19:42] =>  0:47
      CLOCK: [2024-10-31 Do 17:49]--[2024-10-31 Do 18:34] =>  0:45
      :END:
***** DONE Pre-computing advice
      CLOSED: [2024-11-08 Fr 18:54]
      :LOGBOOK:
      CLOCK: [2024-11-05 Di 18:50]--[2024-11-05 Di 23:49] =>  4:59
      CLOCK: [2024-11-05 Di 14:22]--[2024-11-05 Di 15:46] =>  1:24
      CLOCK: [2024-11-04 Mo 22:26]--[2024-11-04 Mo 23:07] =>  0:41
      :END:
      This is something I can do in the background, this shouldn't be too
      difficult.

      Ha. The youthful optimism of the slightly younger me who wrote the above
      words. Concurrent access to the cache is a problem indeed.
      [2024-11-07 Do 19:56]
      I got a little sidetracked into building essentially a very
      simple-minded replacement for cachego that works the way I want it to,
      and as far as I can tell, it does work the way I want it to, so now I
      can try using that one.
*** Search [1/1]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2024-11-14 Do 17:17]--[2024-11-14 Do 18:16] =>  0:59
    CLOCK: [2024-11-13 Mi 18:55]--[2024-11-13 Mi 21:08] =>  2:13
    CLOCK: [2024-11-13 Mi 18:03]--[2024-11-13 Mi 18:54] =>  0:51
    CLOCK: [2024-11-11 Mo 18:03]--[2024-11-11 Mo 18:13] =>  0:10
    CLOCK: [2024-11-10 So 16:47]--[2024-11-11 Mo 17:22] => 24:35
    :END:
    All the tagging and such doesn't do me any good, unless I can browse or
    search that data in a meaningful way.
    [2024-11-11 Mo 18:05]
    In my previous news ticker, this was really slow. I used SQLite's full
    text search feature, which I assume is not inherently slow. But I did have
    a full-text-search-index over about two years worth news from numerous
    sites, and some sites put the entire article into the description field of
    the RSS feed. The entire database was over a Gigabyte in size the last
    time I checked. Searching through that volume of data is going to have a
    cost.
    Earlier this year, I started a toy project to build a log aggregator that
    would gather log files from several machines in one repository and started
    designing a search feature for that.
    To handle searches that might potentially run for quite a while, I had a
    frontend to define my search parameters, submit the search through the web
    UI, and the search would then run asynchronously in a seperate goroutine.
    I could see in the web frontend if the search was still running, finished,
    or if an error had occured. Once it was done, I could display the search
    results in the frontend.
    This sounds like an approach I could use here as well.
    I could also look into limiting the amount of news items that are
    processed for the search. *If* I use the FTS feature of SQLite, I could
    for example only dump a subset of news items into the FTS index, maybe for
    the last month, last couple of months, something like that.
    I would then have to clean older items from the FTS index or generate it
    from scratch periodically.
    In my old news ticker, I had never come around to delete anything,
    really. When I no longer wanted to read a particular feed, I would just
    suspend it; but the news Items from that feed that were already in the
    database and FTS remained there, contributing to its massive size.
    So first of all, I think I should add the option to delete a feed that
    removes all of its associated data from my application, including the
    database, but also from the Bayesian models for Rating and Tagging.

    [2024-11-18 Mo 22:18]
    The search "engine", if you will, seems to work for the moment.
    Next, I'll have to think about how I want to integrate searching into the
    web UI, and how background searches should be run.
**** DONE Execute Searches
     CLOSED: [2024-11-18 Mo 22:17]
     :LOGBOOK:
     CLOCK: [2024-11-18 Mo 22:07]--[2024-11-18 Mo 22:17] =>  0:10
     CLOCK: [2024-11-18 Mo 18:45]--[2024-11-18 Mo 21:28] =>  2:43
     CLOCK: [2024-11-18 Mo 18:18]--[2024-11-18 Mo 18:36] =>  0:18
     CLOCK: [2024-11-16 Sa 18:38]--[2024-11-16 Sa 22:42] =>  4:04
     CLOCK: [2024-11-16 Sa 18:01]--[2024-11-16 Sa 18:25] =>  0:24
     CLOCK: [2024-11-16 Sa 17:29]--[2024-11-16 Sa 17:31] =>  0:02
     CLOCK: [2024-11-16 Sa 14:43]--[2024-11-16 Sa 16:20] =>  1:37
     CLOCK: [2024-11-16 Sa 10:53]--[2024-11-16 Sa 10:57] =>  0:04
     CLOCK: [2024-11-15 Fr 17:14]--[2024-11-15 Fr 22:49] =>  5:35
     :END:
     I did this in a prior toy application, so it is not entirely unknown
     territory.

     [2024-11-15 Fr 17:17]
     As I woke up this morning, I had an idea that I could do something
     vaguely akin to an RDBMS creating a query plan.
     For example, if there are not tags specified in the query, I would
     basically load news Items and try to match each one to the query
     string. If there are tags, I would first load the Items linked to those
     tags, because that would probably be a much smaller number, and then
     proceed to check *those* against my query string.
     If the query string is not a regular expression, I can use the database's
     LIKE clause.
     And so forth. Attempt to order by steps so I need to perform the minimum
     amount of work, offload what I can to the database engine.
     I'll see what I can do.

     As far as the interface goes, I think I should have a method on the
     Database, something like SearchPerform, that gets a Search object as its
     parameter and if successful fills in the results on that object.

     [2024-11-18 Mo 18:34]
     Okay, I have my code at a stage where I /think/ it should what it is
     supposed to. It compiles, and my linters are no longer yelling at it.
     So I am going to write some tests now, to see how hopelessly naive my
     optimism really is.
** Bugs [0/0]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:


